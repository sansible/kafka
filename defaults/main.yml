---

kafka:
  apache_mirror: http://apache.mirror.anlx.net/
  auto_create_topics: "false"
  conf_dir: /home/kafka/etc
  data_dir: /home/kafka/data
  default_replication_factor: 1
  group: kafka
  heap_opts: "-Xmx{{ (ansible_memtotal_mb / 2) | int }}m -Xms{{ (ansible_memtotal_mb / 2) | int }}m"
  id: 1
  jmx_port: 9999
  log_cleanup_interval_mins: 1
  log_dir: /home/kafka/log
  log_flush_interval_messages: 10000
  log_flush_interval_ms: 1000
  log_level: WARN
  log_retention_bytes: 104857600  #100 M
  log_retention_hours: 24
  log_segment_bytes: 104857600
  num_io_threads: 2
  num_network_threads: 2
  num_partitions: 2
  port: 9092
  socket_receive_buffer_bytes: 1048576
  socket_request_max_bytes: 104857600
  socket_send_buffer_bytes: 1048576
  tarball_location: /home/kafka/tmp
  upstart_conf: /etc/init/kafka.conf
  user: kafka
  version_kafka: "0.9.0.0"
  version_scala: "2.11"
  zookeeper_connection_timeout_ms: 1000000
  zookeeper_hosts:
    - localhost

  # If enabled AWS will be used to figure out which host and id should be used
  # Note that you must install the AWS CLI tools on the machine to use this feature
  aws_cluster_autodiscover:
    enabled: false
    # Tag to store the ID/index of the host that gets assigned to a machine
    id_tag_name: KafkaID
    # Ansible's ec2_remote_facts filter
    zookeeper_lookup_filter:
